<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<include resource="org/springframework/boot/logging/logback/defaults.xml"/>
	​<!-- 读取应用程序相关配置-->
	<springProperty scope="context" name="springAppName" source="spring.application.name"/>

	<springProperty scope="context" name="logPipelinePort" source="logstash.pipeline.port" defaultValue="6379"/>
	<springProperty scope="context" name="logPipelineKey" source="logstash.pipeline.key" defaultValue="logstash"/>
	<springProperty scope="context" name="logPipelineIP" source="logstash.pipeline.ip" defaultValue="localhost"/>
	<!-- 文件日志位置 -->
	<property name="LOG_FILE" value="${BUILD_FOLDER:-build}/${springAppName}"/>​
	<!-- 控制台日志格式 -->
	<property name="CONSOLE_LOG_PATTERN" value="%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr([${springAppName:-},%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-Span-Export:-}]){yellow} %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>

	<!-- 控制台日志appender -->
	<appender name="console" class="ch.qos.logback.core.ConsoleAppender">
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<!-- 控制台日志等级 -->
			<level>INFO</level>
		</filter>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN}</pattern>
			<charset>utf8</charset>
		</encoder>
	</appender>
	<!-- 将日志写入文件 appender -->​
	<appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_FILE}</file>
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${LOG_FILE}.%d{yyyy-MM-dd}.gz</fileNamePattern>
			<maxHistory>7</maxHistory>
		</rollingPolicy>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN}</pattern>
			<charset>utf8</charset>
		</encoder>
	</appender>
	<!-- 将日志发送的redis中 appender 具体的相关详细介绍参见 https://github.com/idealo/logback-redis-->
	<appender name="logstash" class="net.logstash.logback.appender.LoggingEventAsyncDisruptorAppender">
		<appender class="de.idealo.logback.appender.RedisBatchAppender">
			<filter>
				<!--日志等级 -->
				<level>INFO</level>
			</filter>
			<!-- redis 连接配置 -->
			<connectionConfig>
				<scheme>NODE</scheme>
				<host>${logPipelineIP}</host>
				<port>${logPipelinePort}</port>
				<key>${logPipelineKey}</key>
			</connectionConfig>
			<encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
				<providers>
					<arguments/>
					<mdc/>
					<pattern>
						<pattern>
							{
							"host": "${HOSTNAME}",
							"severity": "%level",
							"service": "${springAppName:-}",
							"trace": "%X{X-B3-TraceId:-}",
							"span": "%X{X-B3-SpanId:-}",
							"exportable": "%X{X-Span-Export:-}",
							"pid": "${PID:-}",
							"thread": "%thread",
							"class": "%logger{40}",
							"rest": "%message"
							}
						</pattern>
					</pattern>
					<stackTrace/>
				</providers>
			</encoder>
		</appender>
	</appender>
	<root level="INFO">
		<appender-ref ref="console"/>
		<appender-ref ref="logstash"/>
		<appender-ref ref="file"/>
	</root>
</configuration>